Tuning hyper-parameters for f1_macro
MLPClassifier Learning Curve - Poker Hand - on f1_macro
Best parameters found on development set:
{'clf__alpha': 1e-05, 'clf__hidden_layer_sizes': (200,), 'clf__max_iter': 9000, 'clf__solver': 'adam'}
Best Pipeline:
Pipeline(memory=None,
         steps=[('scale',
                 RobustScaler(copy=True, quantile_range=(25.0, 75.0),
                              with_centering=True, with_scaling=True)),
                ('clf',
                 MLPClassifier(activation='relu', alpha=1e-05,
                               batch_size='auto', beta_1=0.9, beta_2=0.999,
                               early_stopping=False, epsilon=1e-08,
                               hidden_layer_sizes=(200,),
                               learning_rate='constant',
                               learning_rate_init=0.001, max_fun=15000,
                               max_iter=9000, momentum=0.9, n_iter_no_change=10,
                               nesterovs_momentum=True, power_t=0.5,
                               random_state=None, shuffle=True, solver='adam',
                               tol=0.0001, validation_fraction=0.1,
                               verbose=False, warm_start=False))],
         verbose=False)
Detailed classification report:
The model is trained on the full development set.
The scores are computed on the full evaluation set.
{'0': {'precision': 0.7213656387665198, 'recall': 0.9660766961651918, 'f1-score': 0.8259773013871374, 'support': 678}, '1': {'precision': 0.9973404255319149, 'recall': 0.9572165806559014, 'f1-score': 0.9768666647790016, 'support': 18021}, '2': {'precision': 0.7100248550124275, 'recall': 0.9618406285072951, 'f1-score': 0.8169685414680649, 'support': 891}, '3': {'precision': 0.9849246231155779, 'recall': 0.9966101694915255, 'f1-score': 0.9907329401853412, 'support': 590}, '4': {'precision': 0.46075085324232085, 'recall': 0.9926470588235294, 'f1-score': 0.6293706293706295, 'support': 136}, '5': {'precision': 0.91, 'recall': 1.0, 'f1-score': 0.9528795811518325, 'support': 91}, '6': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 78}, '7': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 15}, '8': {'precision': 0.2, 'recall': 1.0, 'f1-score': 0.33333333333333337, 'support': 1}, '9': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 0}, 'accuracy': 0.9594653919321009, 'macro avg': {'precision': 0.6984406395668761, 'recall': 0.8874391133643444, 'f1-score': 0.752612899167534, 'support': 20501}, 'weighted avg': {'precision': 0.9713949320076856, 'recall': 0.9594653919321009, 'f1-score': 0.9629880475241608, 'support': 20501}}
[[  655    18     0     0     4     1     0     0     0     0]
 [  252 17250   348     4   153     8     0     0     4     2]
 [    0    28   857     5     1     0     0     0     0     0]
 [    0     0     2   588     0     0     0     0     0     0]
 [    1     0     0     0   135     0     0     0     0     0]
 [    0     0     0     0     0    91     0     0     0     0]
 [    0     0     0     0     0     0    78     0     0     0]
 [    0     0     0     0     0     0     0    15     0     0]
 [    0     0     0     0     0     0     0     0     1     0]
 [    0     0     0     0     0     0     0     0     0     0]]

-----------
Cross-Val Accuracy: 0.99 (+/- 0.02)Cross-Val F1 Accuracy: 0.88 (+/- 0.07)
-----------
Normalized Accuracy: 0.96
Non-Normalized Accuracy: 19670.00